{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\mathrm H^{1}(\\wedge^2\\mathfrak b)=\\mathbb{C}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bggcohomology.bggcomplex import BGGComplex\n",
    "from bggcohomology.la_modules import LieAlgebraCompositeModule, ModuleFactory, BGGCohomology\n",
    "from bggcohomology.cohomology import compute_diff\n",
    "from bggcohomology.la_modules import BGGCohomology\n",
    "from bggcohomology.bggcomplex import BGGComplex\n",
    "from bggcohomology.quantum_center import *\n",
    "from bggcohomology.weight_set import WeightSet\n",
    "from bggcohomology.cohomology import compute_diff\n",
    "import numpy as np\n",
    "\n",
    "BGG = BGGComplex('G2')\n",
    "factory = ModuleFactory(BGG.LA)\n",
    "\n",
    "component_dic = {'b':factory.build_component('b','coad',subset=[])}\n",
    "\n",
    "wedge_components = [[(\"b\",2,'wedge')]]\n",
    "wedge_module = LieAlgebraCompositeModule(factory,wedge_components,component_dic)\n",
    "\n",
    "BGGCohomology(BGG, wedge_module).cohomology_LaTeX(complex_string = r'\\wedge^2\\mathfrak b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ 1]\n",
       "[ 0]\n",
       "[--]\n",
       "[ 0]\n",
       "[-1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohom = BGGCohomology(BGG, wedge_module)\n",
    "\n",
    "sparse, _ = compute_diff(cohom, (0,0), 0, return_sparse=True)\n",
    "dense, _ = compute_diff(cohom, (0,0), 0, return_sparse=False)\n",
    "sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-6, -3): 1,\n",
       " (-5, -3): 1,\n",
       " (-4, -3): 1,\n",
       " (-3, -3): 1,\n",
       " (-5, -2): 1,\n",
       " (-4, -2): 2,\n",
       " (-3, -2): 4,\n",
       " (-2, -2): 1,\n",
       " (-1, -2): 1,\n",
       " (-4, -1): 1,\n",
       " (-3, -1): 3,\n",
       " (-2, -1): 3,\n",
       " (-1, -1): 3,\n",
       " (0, -1): 2,\n",
       " (-1, 0): 2,\n",
       " (0, 0): 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohom.weight_module.dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, -1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense._list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bb16e866704bd399f95ec703242be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00eba30d03b49e2b2d5d01fe07ec02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0cb695743346f892d35d6c0f0f4f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "type A4, table for s=0:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{array}{r|l l}\n",
       "\t{\\scriptstyle i+j=6}&\\mathbb{C}^{33}&\\\\\n",
       "\t{\\scriptstyle i+j=10}&&\\mathbb{C}^{33}\\\\\n",
       "\t\\hline h^{i,j}&{\\scriptstyle j-i=0}&{\\scriptstyle j-i=4}\n",
       "\\end{array}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{array}{r|l l}\n",
       "\t{\\scriptstyle i+j=6}&33&\\\\\n",
       "\t{\\scriptstyle i+j=10}&&33\\\\\n",
       "\t\\hline h^{i,j}&{\\scriptstyle j-i=0}&{\\scriptstyle j-i=4}\n",
       "\\end{array}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{array}{rll}\n",
       "\t\\text{module}&\\text{multiplicity}&\\text{dimension} \\\\ \\hline \\text{all}&&66 \\\\\n",
       "\t\\mathbb{C}&66&1\n",
       "\\end{array}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%prun -D prun.log\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "os.makedirs('pickles', exist_ok=True)\n",
    "os.makedirs('tables', exist_ok=True)\n",
    "\n",
    "# Only compute cohomology for particular highest weight module\n",
    "mu = None\n",
    "#mu=(0,0)\n",
    "\n",
    "# the parameters we actually want to change\n",
    "diagram = 'A4'\n",
    "BGG = BGGComplex(diagram)\n",
    "subset=[]\n",
    "\n",
    "# compute only half of the table, extend by symmetry\n",
    "half_only = True\n",
    "extend_half = half_only\n",
    "\n",
    "# Exclude the top-left to bottom-right diagonal. If s=0, these should all be the trivial rep.\n",
    "exclude_diagonal = True\n",
    "\n",
    "# Display in full form\n",
    "compact = True\n",
    "\n",
    "# Load results if already computed\n",
    "load_pickle = False\n",
    "\n",
    "# Increase max memory size of the pari stack\n",
    "# Set this as high as possible.\n",
    "# pari.allocatemem(10^6,40*10^9)\n",
    "\n",
    "s=0\n",
    "#for method in [0,1]:\n",
    "#for s in itertools.count():\n",
    "method = 0\n",
    "for s in [0]:\n",
    "    picklefile = os.path.join('pickles',f'{diagram}-s{s}-{subset}.pkl')\n",
    "    if load_pickle and os.path.isfile(picklefile):\n",
    "        previous_cohom = pickle.load(open(picklefile, 'rb'))\n",
    "    else:\n",
    "        previous_cohom = None\n",
    "    texfile = os.path.join('tables',f'{diagram}-s{s}-{subset}.tex')\n",
    "    cohom_dic = dict()\n",
    "    with tqdm(all_abijk(BGG,s=s,subset=subset,half_only=half_only)[18:19]) as inner_pbar:\n",
    "        with tqdm(leave=None) as outer_pbar:\n",
    "            map_pbar = tqdm()\n",
    "            for a,b,i,j,k in inner_pbar:\n",
    "                if previous_cohom is not None and (a,b) in previous_cohom:\n",
    "                    cohom_dic[(a,b)]=previous_cohom[(a,b)]\n",
    "                    inner_pbar.update()\n",
    "                    continue\n",
    "                if exclude_diagonal and s==0 and (a==b):\n",
    "                    cohom_dic[(a,b)]=[((0,)*BGG.rank,1)]\n",
    "                    inner_pbar.update()\n",
    "                    continue\n",
    "                inner_pbar.set_description('i+j= %d, j-i = %d'%(a,b))\n",
    "                #coker = Eijk_basis(BGG,j,k,subset=subset,pbar=outer_pbar)\n",
    "                mjk = Mjk(BGG,j,k,subset=subset)\n",
    "                outer_pbar.set_description('Initializing cohomology')\n",
    "                coker=Eijk_basis(BGG,j,k,subset=subset,method=method,sparse=True)\n",
    "                cohom = BGGCohomology(BGG, mjk, \n",
    "                                      coker=coker,pbars = [outer_pbar,map_pbar])\n",
    "                outer_pbar.set_description('Computing cohomology')\n",
    "                cohom_list = cohom.cohomology(i, mu=mu)\n",
    "                cohom_dic[(a,b)] = cohom_list\n",
    "                with open(picklefile, 'wb') as f:\n",
    "                    pickle.dump(cohom_dic,f)   \n",
    "    print('-'*50)\n",
    "    print(f'type {diagram}, table for s={s}:')\n",
    "    cohom = BGGCohomology(BGG)\n",
    "    cohom_dic = extend_from_symmetry(cohom_dic)\n",
    "    latex_dic = {k:cohom.cohom_to_latex(c, compact=compact) for k,c in cohom_dic.items()}\n",
    "    betti_dic = {k:cohom.betti_number(c) for k,c in cohom_dic.items()}\n",
    "    tab1 = display_bigraded_table(latex_dic)\n",
    "    tab2 = display_bigraded_table(betti_dic)\n",
    "    tab3 = display_cohomology_stats(cohom_dic, BGG)\n",
    "    with open(texfile, 'w') as f:\n",
    "        f.write(prepare_texfile([tab1,tab2,tab3],title=f'type {diagram}, s={s}, subset={subset}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100 x 147 sparse matrix over Integer Ring (use the '.str()' method to see the entries)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=10\n",
    "b=4\n",
    "i=3\n",
    "j=7\n",
    "k=-10\n",
    "mjk = Mjk(BGG,j,k,subset=subset)\n",
    "coker=Eijk_basis(BGG,j,k,subset=subset,method=0,sparse=True)\n",
    "cohom = BGGCohomology(BGG, mjk, coker=coker,pbars = [outer_pbar,map_pbar])\n",
    "cohom.coker[( (-1, -2, -3, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "cython"
    }
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "# cython: language_level=2\n",
    "# cython: profile=True\n",
    "\"\"\"\n",
    "Module to compute the differentials of the BGG complex. Implemented in Cython for extra speed, since it\n",
    "is relatively critical for performance.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sage.matrix.constructor import matrix\n",
    "from sage.rings.integer_ring import ZZ\n",
    "from sage.rings.rational import Rational\n",
    "from sage.rings.integer cimport Integer\n",
    "from sage.matrix.matrix_space import MatrixSpace\n",
    "from sage.matrix.matrix_integer_dense cimport Matrix_integer_dense\n",
    "from sage.matrix.matrix_integer_sparse cimport Matrix_integer_sparse\n",
    "from sage.matrix.special import block_matrix\n",
    "from time import perf_counter\n",
    "\n",
    "cpdef compute_action(acting_element, action_source, module, comp_num):\n",
    "    \"\"\"Computes action of a single lie algebra element on a list of elements of the module. \n",
    "    Outputs a new array where indices and coefficients are replaced as per the action. \n",
    "    The output is unsorted, and may contain duplicate entries. \"\"\"\n",
    "\n",
    "    # Initialize array for output\n",
    "    action_image = np.zeros_like(action_source)\n",
    "\n",
    "    # Get component types. Each type has a different action of the Lie algebra\n",
    "    type_list = module.type_lists[comp_num]\n",
    "    cdef image_row = 0 # counter for which row to edit in output\n",
    "    cdef max_rows = len(action_image)\n",
    "\n",
    "    cdef int row,j\n",
    "    for col,mod_type in enumerate(type_list): # compute the action one column at a time\n",
    "        action_tensor = module.action_tensor_dic[mod_type] # retrieve the structure coefficient tensor\n",
    "        for row in range(len(action_source)):\n",
    "            j = action_source[row,col]\n",
    "            s,k,Cijk = action_tensor[acting_element,j]\n",
    "            while s!=0: # if s=0, then there are no non-zero structure coeffs\n",
    "                new_row = action_source[row].copy() # copy row, and change index to k\n",
    "                new_row[col] = k\n",
    "                new_row[-1]*=Cijk # multiply coefficient of element by structure coefficient C_ijk\n",
    "                action_image[image_row] = new_row\n",
    "                if s==-1: # end of the chain, break out of loop\n",
    "                    s=0\n",
    "                else: # still more non-zero C_ijk's to deal with\n",
    "                    s,k,Cijk = action_tensor[s,j]\n",
    "                image_row+=1\n",
    "                if image_row>=max_rows: # double size of image matrix if we run out of space\n",
    "                    action_image = np.concatenate([action_image,np.zeros_like(action_image)])\n",
    "                    max_rows = len(action_image)\n",
    "    return action_image[:image_row] # Only return non-zero rows\n",
    "\n",
    "cdef check_equal(long [:] row1,long [:] row2,int num_cols):\n",
    "    \"\"\"fast check to see if two arrays of given length are equal\"\"\"\n",
    "    cdef int i\n",
    "    for i in range(num_cols):\n",
    "        if row1[i]!=row2[i]:\n",
    "            return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "cdef col_nonzero(long [:] col, int num_rows):\n",
    "    \"\"\"returns non-zero indices of a column. np.nonzero doesn't seem to work well with memoryviews.\"\"\"\n",
    "\n",
    "    indices = np.zeros(num_rows,np.int32)\n",
    "    cdef int i\n",
    "    cdef int j = 0\n",
    "    for i in range(num_rows):\n",
    "        if col[i]!=0:\n",
    "            indices[j]=i\n",
    "            j+=1\n",
    "    return indices[:j]\n",
    "\n",
    "cdef merge_sorted_image(long [:,:] action_image):\n",
    "    \"\"\"Given sorted array, merges adjacent rows which are equal except for last column, \n",
    "    and adds the values of the last column\"\"\"\n",
    "    merged_image = np.zeros_like(action_image)\n",
    "\n",
    "    cdef long[:] old_row\n",
    "    cdef long[:] row\n",
    "    old_row = np.zeros_like(action_image[0])-1\n",
    "\n",
    "    cdef int row_number = -1\n",
    "    cdef int num_cols = action_image.shape[1]-1\n",
    "    cdef int num_rows = action_image.shape[0]\n",
    "\n",
    "    cdef int i\n",
    "    for i in range(num_rows):\n",
    "        row = action_image[i]\n",
    "        if row[-1]!=0:\n",
    "            if check_equal(row,old_row,num_cols): # if previous and current row are equal, add last column to result\n",
    "                merged_image[row_number,-1] += row[-1]\n",
    "            else:\n",
    "                row_number+=1\n",
    "                merged_image[row_number]=row\n",
    "                old_row = row\n",
    "    row_number+=1\n",
    "    non_zero_inds = col_nonzero(merged_image[:row_number,-1],row_number) # Only return rows where column is non-zero\n",
    "    return merged_image[non_zero_inds,:]\n",
    "\n",
    "def sort_merge(action_image):\n",
    "    \"\"\"Sorts array, ignoring last column and merges rows which are equal, summing in the last column\"\"\"\n",
    "    action_image = action_image[np.lexsort(np.transpose(action_image[:,:-1]))]\n",
    "    return merge_sorted_image(action_image)\n",
    "\n",
    "cdef permutation_sign(long [:] row,int num_cols):\n",
    "    \"\"\"Computes the sign of a permutation using bubble sort (efficient for extremely short inputs)\"\"\"\n",
    "    cdef int sign = 1\n",
    "    cdef int i,j\n",
    "    for i in range(num_cols):\n",
    "        for j in range(i+1,num_cols):\n",
    "            if row[i]==row[j]: # if there are duplicate entries then sign is 0 per definition\n",
    "                return 0\n",
    "            elif row[i]>row[j]: # For each swap we have to do, the sign changes by -1.\n",
    "                sign*=-1\n",
    "    return sign\n",
    "\n",
    "cdef sort_cols(module, action_image,comp_num):\n",
    "    \"\"\"Sort all the entries of each tensor component. If tensor component is a wedge power, then\n",
    "    mutliply coefficient by sign of permutation sorting the row.\"\"\"\n",
    "    cdef int col_min = 0\n",
    "    cdef int num_rows = len(action_image)\n",
    "    cdef int i\n",
    "    cdef long[:] row\n",
    "\n",
    "    for _,cols,mod_type in module.components[comp_num]:\n",
    "        if cols>1: # List with one item is always sorted\n",
    "            if mod_type == 'wedge':\n",
    "                for i in range(num_rows):\n",
    "                    row = action_image[i,col_min:col_min+cols]\n",
    "                    action_image[i,-1]*=permutation_sign(row,cols) # Change coefficient by sign of permutation\n",
    "            action_image[:,col_min:col_min+cols] = np.sort(action_image[:,col_min:col_min+cols]) # sort the rows\n",
    "        col_min+=cols\n",
    "\n",
    "cpdef action_on_basis(pbw_elt,wmbase,module,factory,comp_num):\n",
    "    \"\"\"Computes the action of an element of U(n) in PBW order on a basis of the weight component.\n",
    "    Input is the PBW element, the basis of the weight component,\n",
    "    the factory that created the module, and the number of the direct sum component\"\"\"\n",
    "\n",
    "    num_cols = wmbase.shape[1]\n",
    "    action_list = []\n",
    "    action_source = np.zeros((wmbase.shape[0], num_cols+2),np.int64)\n",
    "    action_source[:,:num_cols] = wmbase\n",
    "    action_source[:,num_cols] = np.arange(len(wmbase))\n",
    "    action_source[:,-1] = 1\n",
    "\n",
    "    # Compute action for each monomial seperately, and then sum results\n",
    "    for monomial,coefficient in pbw_elt.monomial_coefficients().items():\n",
    "        action_image = action_source.copy()\n",
    "        action_image[:,-1]*=coefficient # mutliply results by coefficient of monomial\n",
    "        for term in monomial.to_word_list()[::-1]: # Right action, so we take terms of the monomial in inverse order\n",
    "            index = factory.root_to_index[term] # get the index of the term\n",
    "            action_image = compute_action(index, action_image, module, comp_num) # compute the action\n",
    "        action_list.append(action_image)\n",
    "    action_image = np.concatenate(action_list) # concatenate and merge is equivalent to summing the results.\n",
    "    if len(action_image)==0: # merging gives errors for empty matrices\n",
    "        return action_image\n",
    "    else:\n",
    "        sort_cols(module,action_image,comp_num) # Sort and merge\n",
    "        action_image = sort_merge(action_image)\n",
    "\n",
    "        return action_image\n",
    "\n",
    "def check_weights(module,action_image):\n",
    "    weights = set()\n",
    "    for row in action_image[:,:-2]:\n",
    "        mu = sum(module.weight_dic[s] for s in row)\n",
    "        weights.add(tuple(mu))\n",
    "    if len(weights)>1:\n",
    "        raise ValueError(\"Found too many weights :(\")\n",
    "\n",
    "def compute_diff_new(cohom, mu, i, return_sparse=False):\n",
    "    \"\"\"\"\n",
    "    Computes the BGG differential associated to a BGGCohomology object, weight mu and degree i.\n",
    "    The matrix produced is of the correct rank, but omits some rows consisting entirely of zeros.\n",
    "    In order to correctly compute kernel, the dimension of the source space is therefore also returned.\n",
    "    \"\"\"\n",
    "    # aliases\n",
    "    BGG = cohom.BGG\n",
    "    module = cohom.weight_module\n",
    "    factory =  module.factory\n",
    "\n",
    "    # weights associated to each vertex of the Bruhat graph\n",
    "    vertex_weights = cohom.weight_set.get_vertex_weights(mu)\n",
    "\n",
    "    # maps of the BGG complex\n",
    "    maps = BGG._maps[mu]\n",
    "\n",
    "    # for each vertex, get the arrows in the Bruhat graph going out of it.\n",
    "    column = BGG.column[i]\n",
    "    delta_i_arrows = [(w, [arrow for arrow in BGG.arrows if arrow[0] == w]) for w in column]\n",
    "\n",
    "    # Look up vertex weights for the target column\n",
    "    target_column = BGG.column[i+1]\n",
    "    target_col_dic = {w:vertex_weights[w] for w in target_column}\n",
    "\n",
    "    # To give the weights in the target column a unique index, we compute\n",
    "    # an offset for each weight component in the target column\n",
    "    offset = 0\n",
    "    for w,mu in target_col_dic.items():\n",
    "        target_col_dic[w] = offset\n",
    "        if cohom.has_coker and (mu in cohom.coker):\n",
    "            offset+=cohom.coker[mu].nrows() # Dimension of quotient is number of rows\n",
    "        else:\n",
    "            if mu in module.dimensions:\n",
    "                offset+=module.dimensions[mu]\n",
    "\n",
    "    # Compute dimension of source space by adding dimensions of weight components in the column\n",
    "    source_dim = 0\n",
    "    for w in column:\n",
    "        initial_vertex = vertex_weights[w]\n",
    "        if initial_vertex in cohom.weights:\n",
    "            if cohom.has_coker and (initial_vertex in cohom.coker):\n",
    "                source_dim += cohom.coker[initial_vertex].nrows() # dimension of quotient is number of rows\n",
    "            else:\n",
    "                source_dim += cohom.weight_module.dimensions[initial_vertex]\n",
    "\n",
    "\n",
    "    offset = 0\n",
    "    diff_dict = {}\n",
    "    for w, arrows in delta_i_arrows:\n",
    "        initial_vertex = vertex_weights[w]  # weight of vertex\n",
    "        if initial_vertex in cohom.weights:  # Ensure weight component isn't empty\n",
    "            for a in arrows: # Compute image for each arrow\n",
    "                final_vertex = vertex_weights[a[1]]\n",
    "\n",
    "                sign = BGG.signs[a] # Multiply everything by the sign of the map in BGG complex\n",
    "\n",
    "                comp_offset_s = 0\n",
    "\n",
    "                for comp_num,weight_comp in module.weight_components[initial_vertex]:\n",
    "                    # compute the action of the PBW element\n",
    "                    # map is multiplied by sign. Need to convert sign to Rational to avoid errors in newer sage version\n",
    "                    basis_action = action_on_basis(maps[a]*Rational(sign),weight_comp,module,factory,comp_num)\n",
    "\n",
    "                    basis_action[:,-2] += comp_offset_s # update source\n",
    "                    initial_dimension = module.dimensions_components[comp_num][initial_vertex]\n",
    "                    comp_offset_s += initial_dimension\n",
    "\n",
    "                    # If there is a cokernel, we have reduce the image of the action\n",
    "                    # to the basis of the quotient module\n",
    "                    if cohom.has_coker:\n",
    "                        bas2 = coker_reduce_new(\n",
    "                            cohom.weight_module,cohom.coker, basis_action,\n",
    "                            initial_vertex, final_vertex, component=comp_num\n",
    "                        )\n",
    "                        bas = bas2\n",
    "\n",
    "\n",
    "\n",
    "                    # The cokernel reduction automatically converts to sparse format\n",
    "                    # In the non-cokernel case we still have to do this manually\n",
    "                    if len(basis_action)>0:\n",
    "                        if not cohom.has_coker:\n",
    "                            target_basis_dic = module.weight_comp_index_numbers[final_vertex]\n",
    "                            basis_action = multiindex_to_index(basis_action,target_basis_dic,comp_num)\n",
    "                            bas = dok_to_sage_sparse(basis_action)\n",
    "                    key = (initial_vertex,final_vertex,comp_num)\n",
    "                    if key in diff_dict:\n",
    "                        raise ValueError(\"Found duplicate key in diff_dict\")\n",
    "                    diff_dict[key] = bas\n",
    "\n",
    "\n",
    "    d_sparse = assemble_block_diff(diff_dict)\n",
    "\n",
    "    return d_sparse, source_dim\n",
    "\n",
    "cdef multiindex_to_index(long [:,:] action_image, target_basis_dic, long component):\n",
    "    cdef size_t num_rows = action_image.shape[0]\n",
    "    cdef long[:,:] lookup_map = np.concatenate(\n",
    "        [action_image[:,:-2], np.ones((num_rows,1), dtype=np.int_) * component], axis=1\n",
    "    )\n",
    "    cdef long[:] target_inds = np.zeros(num_rows, dtype=np.int_)\n",
    "    cdef size_t j\n",
    "    for j in range(num_rows):\n",
    "        target_inds[j] = target_basis_dic[tuple(lookup_map[j])]\n",
    "    cdef long[:,:] result = np.stack([target_inds,action_image[:,-2], action_image[:,-1]],axis=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "# def dok_to_sage_sparse(dok_matrix):\n",
    "#     return matrix(ZZ, {(a,b): c for a, b, c in np.array(dok_matrix)}, sparse=True)\n",
    "\n",
    "def dok_to_sage_sparse(dok_matrix):\n",
    "    try:\n",
    "        n_rows = np.max(dok_matrix[:,0]) + 1\n",
    "        n_cols = np.max(dok_matrix[:,1]) + 1\n",
    "    except ValueError:  # empty matrix\n",
    "        n_rows = 0\n",
    "        n_cols = 0\n",
    "        \n",
    "    result = matrix(ZZ, n_rows, n_cols, sparse=True)\n",
    "    if n_rows > 0:\n",
    "        for a, b, c in np.array(dok_matrix):\n",
    "            result[a,b] += c\n",
    "    return result\n",
    "\n",
    "def dok_to_sage_dense(dok_matrix):\n",
    "    return matrix(ZZ, {(a,b): c for a, b, c in np.array(dok_matrix)}, sparse=False)\n",
    "\n",
    "def assemble_block_diff(diff_dict):\n",
    "    initial_vertices = set()\n",
    "    final_vertices = set()\n",
    "    pairs_sums = dict()\n",
    "    for (init,final,comp_num),val in diff_dict.items():\n",
    "        initial_vertices.add(init)\n",
    "        final_vertices.add(final)\n",
    "        try:\n",
    "            pairs_sums[(init,final)] += val\n",
    "        except KeyError:\n",
    "            pairs_sums[(init,final)] = val\n",
    "        \n",
    "    block_rows = []\n",
    "    for final in final_vertices:\n",
    "        block_row= []\n",
    "        for init in initial_vertices:\n",
    "            if (init,final) in pairs_sums:\n",
    "                block_row.append(pairs_sums[(init,final)])\n",
    "            else:\n",
    "                block_row.append(Integer(0))\n",
    "        block_rows.append(block_row)\n",
    "    sparse_new_block= block_matrix(block_rows, sparse=True)\n",
    "    return sparse_new_block\n",
    "\n",
    "def coker_reduce_new(target_module, coker, long[:,:] action_image, mu0, mu1, component=0):\n",
    "    \"\"\"Projects source and target of an action in the coker quotient coker(f), f:M->N.\n",
    "    Returns action in the basis of the cokernel.\n",
    "    `source_module` is the module M\n",
    "    `target_module` is the module N\n",
    "    `coker` is a dictionary encoding a basis of the coker in each weight component of N\n",
    "    `action_image` is what action_on_basis returns.\n",
    "    `component` is the index of the direct sum component\n",
    "    We assume we acted with a map `mu0`->`mu1` in action_on_basis.\n",
    "    \"\"\"\n",
    "    # the input is always of shape [i1,i2,..,ik,j,c] where i denotes the indices\n",
    "    # of the target, j the source index, and c the coefficient.\n",
    "    # then `num_cols` denotes this number k.\n",
    "    cdef size_t num_cols = action_image.shape[1]-2\n",
    "\n",
    "    # If mu1 is not in the module, then it has to be zero\n",
    "    if mu1 not in target_module.weight_components:\n",
    "        return []\n",
    "\n",
    "    # Convert the sets of indices [i1,...,ik] into a single index i for the whole weight component\n",
    "    # We do this by looking the index i up in a dictionary.\n",
    "    target_basis_dic = target_module.weight_comp_index_numbers[mu1]\n",
    "    cdef long[:,:] action_image_target\n",
    "\n",
    "    action_image_target = multiindex_to_index(\n",
    "        action_image, target_basis_dic, component\n",
    "    )\n",
    "    cdef Matrix_integer_sparse res = dok_to_sage_sparse(action_image_target)\n",
    "    cdef size_t max_s = res.ncols()\n",
    "    cdef size_t max_t = res.nrows()\n",
    "\n",
    "    # If mu0 is in the cokernel dictionary, express the action in the basis of the quotient\n",
    "    # If not, then the basis of the quotient is equal to the basis of the module, so there's nothing to do\n",
    "    if mu0 in coker:\n",
    "        # res has shape max_t, max_s\n",
    "        res = res*(coker[mu0][:,:max_s].T)\n",
    "    \n",
    "\n",
    "    # If mu1 is in the cokernel dictionary, then reduce the image to the quotient\n",
    "    # We do this by multiplying by the matrix encoding the basis of the cokernel\n",
    "    # If it's not in the dictionary, no reduction is necessary.\n",
    "    if mu1 in coker:\n",
    "        res = coker[mu1][:,:max_t]*res\n",
    "    # return matrix(ZZ, res.dict())\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file 'prun.log'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         5344830 function calls (5337846 primitive calls) in 4.818 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     1074    2.208    0.002    2.252    0.002 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:20(compute_action)\n",
      "      182    0.684    0.004    0.973    0.005 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:119(sort_cols)\n",
      "      182    0.302    0.002    0.574    0.003 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:269(multiindex_to_index)\n",
      "       19    0.255    0.013    0.257    0.014 {method 'stack' of 'sage.matrix.matrix1.Matrix' objects}\n",
      "      280    0.186    0.001    0.191    0.001 {method 'augment' of 'sage.matrix.matrix_sparse.Matrix_sparse' objects}\n",
      "      182    0.161    0.001    0.852    0.005 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:326(coker_reduce_new)\n",
      "   612472    0.120    0.000    0.181    0.000 stringsource:657(memoryview_cwrapper)\n",
      "   329696    0.113    0.000    0.238    0.000 stringsource:403(__getitem__)\n",
      "14096/7112    0.097    0.000    0.135    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "      182    0.087    0.000    0.126    0.001 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:75(merge_sorted_image)\n",
      "      182    0.080    0.000    0.099    0.001 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:285(dok_to_sage_sparse)\n",
      "   686600    0.064    0.000    0.064    0.000 stringsource:345(__cinit__)\n",
      "   329334    0.047    0.000    0.075    0.000 stringsource:393(get_item_pointer)\n",
      "        1    0.040    0.040    0.498    0.498 special.py:1746(block_matrix)\n",
      "   329696    0.036    0.000    0.036    0.000 stringsource:666(_unellipsify)\n",
      "   611198    0.035    0.000    0.035    0.000 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:107(permutation_sign)\n",
      "   686600    0.034    0.000    0.034    0.000 stringsource:372(__dealloc__)\n",
      "     1621    0.030    0.000    0.031    0.000 matrix_space.py:819(_element_constructor_)\n",
      "    74128    0.029    0.000    0.036    0.000 stringsource:999(memoryview_fromslice)\n",
      "   329334    0.028    0.000    0.028    0.000 stringsource:910(pybuffer_index)\n",
      "   612654    0.028    0.000    0.028    0.000 stringsource:663(memoryview_check)\n",
      "      182    0.018    0.000    3.443    0.019 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:136(action_on_basis)\n",
      "   294086    0.014    0.000    0.014    0.000 stringsource:979(convert_item_to_object)\n",
      "        1    0.013    0.013    4.817    4.817 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:173(compute_diff_new)\n",
      "      294    0.009    0.000    0.009    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
      "      182    0.008    0.000    0.191    0.001 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:102(sort_merge)\n",
      "        1    0.008    0.008    0.506    0.506 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:302(assemble_block_diff)\n",
      "   139893    0.007    0.000    0.007    0.000 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:54(check_equal)\n",
      "     1321    0.007    0.000    0.013    0.000 matrix_space.py:513(__classcall__)\n",
      "      294    0.006    0.000    0.006    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "     3401    0.005    0.000    0.031    0.000 numeric.py:76(zeros_like)\n",
      "    74128    0.005    0.000    0.005    0.000 stringsource:976(__dealloc__)\n",
      "     1321    0.004    0.000    0.006    0.000 matrix_space.py:87(get_matrix_class)\n",
      "    73584    0.003    0.000    0.003    0.000 stringsource:559(__get__)\n",
      "     3401    0.003    0.000    0.003    0.000 {built-in method numpy.zeros}\n",
      "     3401    0.002    0.000    0.010    0.000 <__array_function__ internals>:177(empty_like)\n",
      "     3401    0.002    0.000    0.037    0.000 <__array_function__ internals>:177(zeros_like)\n",
      "      362    0.002    0.000    0.002    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     3583    0.002    0.000    0.013    0.000 <__array_function__ internals>:177(copyto)\n",
      "    38696    0.002    0.000    0.002    0.000 stringsource:518(__getbuffer__)\n",
      "      436    0.002    0.000    0.004    0.000 indexed_free_monoid.py:475(_sorted_items)\n",
      "      182    0.002    0.000    0.002    0.000 _home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.pyx:63(col_nonzero)\n",
      "     2509    0.002    0.000    0.021    0.000 <__array_function__ internals>:177(concatenate)\n",
      "    35248    0.002    0.000    0.002    0.000 stringsource:605(__len__)\n",
      "      182    0.002    0.000    0.005    0.000 shape_base.py:357(stack)\n",
      "        1    0.001    0.001    4.818    4.818 <string>:1(<module>)\n",
      "      362    0.001    0.000    0.004    0.000 fromnumeric.py:69(_wrapreduction)\n",
      "      399    0.001    0.000    0.001    0.000 quantum_center.py:421(__contains__)\n",
      "      872    0.001    0.000    0.001    0.000 indexed_free_monoid.py:504(__hash__)\n",
      "     2761    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "      436    0.001    0.000    0.005    0.000 indexed_free_monoid.py:336(to_word_list)\n",
      "      436    0.001    0.000    0.001    0.000 indexed_free_monoid.py:355(<listcomp>)\n",
      "      399    0.001    0.000    0.001    0.000 quantum_center.py:404(__getitem__)\n",
      "      294    0.001    0.000    0.016    0.000 fromnumeric.py:852(sort)\n",
      "      120    0.001    0.000    0.001    0.000 {built-in method numpy.array}\n",
      "      362    0.001    0.000    0.005    0.000 fromnumeric.py:2675(amax)\n",
      "      840    0.001    0.000    0.001    0.000 {built-in method numpy.asanyarray}\n",
      "      544    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
      "     3583    0.001    0.000    0.001    0.000 multiarray.py:1071(copyto)\n",
      "      436    0.001    0.000    0.001    0.000 {method 'sort' of 'list' objects}\n",
      "     3401    0.001    0.000    0.001    0.000 numeric.py:72(_zeros_like_dispatcher)\n",
      "      412    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\n",
      "     3354    0.000    0.000    0.000    0.000 matrix_space.py:2108(nrows)\n",
      "      838    0.000    0.000    0.000    0.000 pbw.py:147(_basis_key)\n",
      "      838    0.000    0.000    0.001    0.000 pbw.py:196(_monoid_key)\n",
      "     2509    0.000    0.000    0.000    0.000 multiarray.py:148(concatenate)\n",
      "     3401    0.000    0.000    0.000    0.000 multiarray.py:80(empty_like)\n",
      "      294    0.000    0.000    0.017    0.000 <__array_function__ internals>:177(sort)\n",
      "      412    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:404(parent)\n",
      "      182    0.000    0.000    0.006    0.000 <__array_function__ internals>:177(stack)\n",
      "      362    0.000    0.000    0.001    0.000 stringsource:710(memview_slice)\n",
      "     3354    0.000    0.000    0.000    0.000 matrix_space.py:2096(ncols)\n",
      "      182    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "      362    0.000    0.000    0.006    0.000 <__array_function__ internals>:177(amax)\n",
      "      182    0.000    0.000    0.001    0.000 numeric.py:149(ones)\n",
      "      120    0.000    0.000    0.001    0.000 weight_set.py:152(dot_action)\n",
      "      182    0.000    0.000    0.000    0.000 shape_base.py:424(<setcomp>)\n",
      "      436    0.000    0.000    0.000    0.000 indexed_generators.py:201(print_options)\n",
      "      182    0.000    0.000    0.000    0.000 shape_base.py:432(<listcomp>)\n",
      "      182    0.000    0.000    0.001    0.000 shape_base.py:348(_stack_dispatcher)\n",
      "      594    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "      182    0.000    0.000    0.001    0.000 <__array_function__ internals>:177(transpose)\n",
      "      182    0.000    0.000    0.001    0.000 shape_base.py:420(<listcomp>)\n",
      "      412    0.000    0.000    0.001    0.000 rational_field.py:1684(is_RationalField)\n",
      "      362    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
      "      182    0.000    0.000    0.056    0.000 <__array_function__ internals>:177(lexsort)\n",
      "     1670    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "      412    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "      182    0.000    0.000    0.000    0.000 fromnumeric.py:51(_wrapfunc)\n",
      "        1    0.000    0.000    0.000    0.000 special.py:1535(_determine_block_matrix_grid)\n",
      "     1621    0.000    0.000    0.000    0.000 matrix_space.py:1856(is_sparse)\n",
      "      182    0.000    0.000    0.000    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "        1    0.000    0.000    0.001    0.001 weight_set.py:274(get_vertex_weights)\n",
      "      182    0.000    0.000    0.001    0.000 fromnumeric.py:601(transpose)\n",
      "      872    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "     1201    0.000    0.000    0.000    0.000 {sage.structure.element.is_Matrix}\n",
      "      182    0.000    0.000    0.000    0.000 multiarray.py:416(lexsort)\n",
      "      182    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "      666    0.000    0.000    0.000    0.000 {method 'parent' of 'sage.structure.element.Element' objects}\n",
      "      412    0.000    0.000    0.000    0.000 {sage.rings.integer_ring.is_IntegerRing}\n",
      "      294    0.000    0.000    0.000    0.000 fromnumeric.py:848(_sort_dispatcher)\n",
      "      182    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "      230    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "      362    0.000    0.000    0.000    0.000 fromnumeric.py:2670(_amax_dispatcher)\n",
      "        1    0.000    0.000    4.818    4.818 {built-in method builtins.exec}\n",
      "      544    0.000    0.000    0.000    0.000 stringsource:992(__get__)\n",
      "      182    0.000    0.000    0.000    0.000 fromnumeric.py:597(_transpose_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'subdivide' of 'sage.matrix.matrix2.Matrix' objects}\n",
      "      140    0.000    0.000    0.000    0.000 {method 'base_ring' of 'sage.matrix.matrix0.Matrix' objects}\n",
      "       70    0.000    0.000    0.000    0.000 {method 'is_sparse' of 'sage.matrix.matrix0.Matrix' objects}\n",
      "      140    0.000    0.000    0.000    0.000 {method 'ncols' of 'sage.matrix.matrix0.Matrix' objects}\n",
      "      140    0.000    0.000    0.000    0.000 {method 'nrows' of 'sage.matrix.matrix0.Matrix' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {sage.rings.ring.is_Ring}\n",
      "       21    0.000    0.000    0.000    0.000 special.py:1994(<genexpr>)\n",
      "        1    0.000    0.000    4.817    4.817 {_home_rik__sage_temp_rik_math_1898836_tmp_f18q0ei8_pyx_0.compute_diff_new}\n",
      "        2    0.000    0.000    0.000    0.000 {sage.misc.misc_c.running_total}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
     ]
    }
   ],
   "source": [
    "%%prun -D prun.log\n",
    "sparse_new, source_dim = compute_diff_new(cohom,(0,0,0,0),i,return_sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "import io\n",
    "\n",
    "result = io.StringIO()\n",
    "stats = pstats.Stats('prun.log',stream=result)\n",
    "stats.sort_stats(\"cumulative\").print_stats()\n",
    "result=result.getvalue()\n",
    "# chop the string into a csv-like buffer\n",
    "result='ncalls'+result.split('ncalls')[-1]\n",
    "result='\\n'.join([','.join(line.rstrip().split(None,5)) for line in result.split('\\n')])\n",
    "# save it to disk\n",
    " \n",
    "with open('profile.csv', 'w+') as f:\n",
    "    #f=open(result.rsplit('.')[0]+'.csv','w')\n",
    "    f.write(result)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913, 1277)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_new.rank(), source_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bggcohomology.cohomology import compute_diff\n",
    "\n",
    "coker_old=Eijk_basis(BGG,j,k,subset=subset,method=0,sparse=False)\n",
    "cohom_old = BGGCohomology(BGG, mjk, coker=coker_old,pbars = [outer_pbar,map_pbar])\n",
    "sparse_old = compute_diff(cohom_old,(0,0,0,0),i,return_sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913, 913)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_old[0].rank(),sparse_new_block.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file 'prun.log'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         6118787 function calls (6111259 primitive calls) in 5.447 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     1074    2.295    0.002    2.338    0.002 cohomology.pyx:18(compute_action)\n",
      "      182    1.208    0.007    1.582    0.009 cohomology.pyx:336(coker_reduce)\n",
      "      182    0.672    0.004    0.941    0.005 cohomology.pyx:117(sort_cols)\n",
      "      363    0.199    0.001    0.310    0.001 cohomology.pyx:73(merge_sorted_image)\n",
      "53059/45531    0.128    0.000    0.261    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        1    0.107    0.107    5.447    5.447 cohomology.pyx:171(compute_diff)\n",
      "   613015    0.105    0.000    0.163    0.000 stringsource:657(memoryview_cwrapper)\n",
      "   294086    0.101    0.000    0.214    0.000 stringsource:403(__getitem__)\n",
      "   775247    0.067    0.000    0.067    0.000 stringsource:345(__cinit__)\n",
      "   162232    0.062    0.000    0.079    0.000 stringsource:999(memoryview_fromslice)\n",
      "        1    0.047    0.047    0.047    0.047 matrix_space.py:819(_element_constructor_)\n",
      "   294086    0.041    0.000    0.067    0.000 stringsource:393(get_item_pointer)\n",
      "    38584    0.038    0.000    0.038    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "   775247    0.036    0.000    0.036    0.000 stringsource:372(__dealloc__)\n",
      "   611198    0.035    0.000    0.035    0.000 cohomology.pyx:105(permutation_sign)\n",
      "   294086    0.034    0.000    0.034    0.000 stringsource:666(_unellipsify)\n",
      "    38584    0.030    0.000    0.080    0.000 fromnumeric.py:69(_wrapreduction)\n",
      "   613015    0.028    0.000    0.028    0.000 stringsource:663(memoryview_check)\n",
      "   294086    0.026    0.000    0.026    0.000 stringsource:910(pybuffer_index)\n",
      "    38584    0.021    0.000    0.101    0.000 fromnumeric.py:2305(any)\n",
      "      182    0.016    0.000    3.493    0.019 cohomology.pyx:134(action_on_basis)\n",
      "    38584    0.015    0.000    0.145    0.000 <__array_function__ internals>:177(any)\n",
      "   273219    0.014    0.000    0.014    0.000 cohomology.pyx:52(check_equal)\n",
      "   258838    0.012    0.000    0.012    0.000 stringsource:979(convert_item_to_object)\n",
      "      363    0.011    0.000    0.386    0.001 cohomology.pyx:100(sort_merge)\n",
      "   162232    0.011    0.000    0.011    0.000 stringsource:976(__dealloc__)\n",
      "    38584    0.009    0.000    0.009    0.000 fromnumeric.py:70(<dictcomp>)\n",
      "      294    0.008    0.000    0.008    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
      "   162232    0.008    0.000    0.008    0.000 stringsource:559(__get__)\n",
      "     3764    0.007    0.000    0.035    0.000 numeric.py:76(zeros_like)\n",
      "   126984    0.006    0.000    0.006    0.000 stringsource:518(__getbuffer__)\n",
      "      294    0.006    0.000    0.006    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "      363    0.005    0.000    0.005    0.000 cohomology.pyx:61(col_nonzero)\n",
      "    38584    0.004    0.000    0.004    0.000 fromnumeric.py:2300(_any_dispatcher)\n",
      "     3764    0.003    0.000    0.003    0.000 {built-in method numpy.zeros}\n",
      "     3764    0.003    0.000    0.012    0.000 <__array_function__ internals>:177(empty_like)\n",
      "    39892    0.003    0.000    0.003    0.000 {method 'items' of 'dict' objects}\n",
      "     3764    0.003    0.000    0.042    0.000 <__array_function__ internals>:177(zeros_like)\n",
      "     3764    0.002    0.000    0.013    0.000 <__array_function__ internals>:177(copyto)\n",
      "    35248    0.002    0.000    0.002    0.000 stringsource:605(__len__)\n",
      "      436    0.002    0.000    0.004    0.000 indexed_free_monoid.py:475(_sorted_items)\n",
      "     2161    0.001    0.000    0.018    0.000 <__array_function__ internals>:177(concatenate)\n",
      "      399    0.001    0.000    0.001    0.000 quantum_center.py:421(__contains__)\n",
      "      872    0.001    0.000    0.001    0.000 indexed_free_monoid.py:504(__hash__)\n",
      "      436    0.001    0.000    0.001    0.000 indexed_free_monoid.py:355(<listcomp>)\n",
      "      436    0.001    0.000    0.006    0.000 indexed_free_monoid.py:336(to_word_list)\n",
      "      294    0.001    0.000    0.015    0.000 fromnumeric.py:852(sort)\n",
      "      120    0.001    0.000    0.001    0.000 {built-in method numpy.array}\n",
      "      399    0.001    0.000    0.001    0.000 quantum_center.py:404(__getitem__)\n",
      "     3764    0.001    0.000    0.001    0.000 numeric.py:72(_zeros_like_dispatcher)\n",
      "      364    0.001    0.000    0.002    0.000 <__array_function__ internals>:177(transpose)\n",
      "     3764    0.001    0.000    0.001    0.000 multiarray.py:1071(copyto)\n",
      "      436    0.001    0.000    0.002    0.000 {method 'sort' of 'list' objects}\n",
      "     3764    0.001    0.000    0.001    0.000 multiarray.py:80(empty_like)\n",
      "      838    0.001    0.000    0.001    0.000 pbw.py:147(_basis_key)\n",
      "      364    0.001    0.000    0.001    0.000 fromnumeric.py:51(_wrapfunc)\n",
      "      838    0.000    0.000    0.001    0.000 pbw.py:196(_monoid_key)\n",
      "      294    0.000    0.000    0.016    0.000 <__array_function__ internals>:177(sort)\n",
      "      120    0.000    0.000    0.001    0.000 weight_set.py:152(dot_action)\n",
      "     2161    0.000    0.000    0.000    0.000 multiarray.py:148(concatenate)\n",
      "      364    0.000    0.000    0.064    0.000 <__array_function__ internals>:177(lexsort)\n",
      "      364    0.000    0.000    0.001    0.000 fromnumeric.py:601(transpose)\n",
      "      436    0.000    0.000    0.000    0.000 indexed_generators.py:201(print_options)\n",
      "      364    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "      368    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.001    0.001 weight_set.py:274(get_vertex_weights)\n",
      "      364    0.000    0.000    0.000    0.000 multiarray.py:416(lexsort)\n",
      "      364    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "      872    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "      436    0.000    0.000    0.000    0.000 {method 'parent' of 'sage.structure.element.Element' objects}\n",
      "      294    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "      364    0.000    0.000    0.000    0.000 fromnumeric.py:597(_transpose_dispatcher)\n",
      "      294    0.000    0.000    0.000    0.000 fromnumeric.py:848(_sort_dispatcher)\n",
      "        1    0.000    0.000    5.447    5.447 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 matrix_space.py:513(__classcall__)\n",
      "        1    0.000    0.000    0.000    0.000 matrix_space.py:87(get_matrix_class)\n",
      "        1    0.000    0.000    5.447    5.447 <string>:1(<module>)\n",
      "        1    0.000    0.000    5.447    5.447 {bggcohomology.cohomology.compute_diff}\n",
      "        1    0.000    0.000    0.000    0.000 matrix_space.py:1856(is_sparse)\n",
      "        2    0.000    0.000    0.000    0.000 matrix_space.py:2096(ncols)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:404(parent)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\n",
      "        2    0.000    0.000    0.000    0.000 matrix_space.py:2108(nrows)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 rational_field.py:1684(is_RationalField)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        1    0.000    0.000    0.000    0.000 {sage.rings.integer_ring.is_IntegerRing}"
     ]
    }
   ],
   "source": [
    "%%prun -D prun.log\n",
    "sparse_old,source_dim = compute_diff(cohom_old,(0,0,0,0),i,return_sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "import io\n",
    "\n",
    "result = io.StringIO()\n",
    "stats = pstats.Stats('prun.log',stream=result)\n",
    "stats.sort_stats(\"cumulative\").print_stats()\n",
    "result=result.getvalue()\n",
    "# chop the string into a csv-like buffer\n",
    "result='ncalls'+result.split('ncalls')[-1]\n",
    "result='\\n'.join([','.join(line.rstrip().split(None,5)) for line in result.split('\\n')])\n",
    "# save it to disk\n",
    " \n",
    "with open('profile_old.csv', 'w+') as f:\n",
    "    #f=open(result.rsplit('.')[0]+'.csv','w')\n",
    "    f.write(result)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix(ZZ,{(0,0):1,(0,0):2,(0,0):3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2040 x 1635 sparse matrix over Integer Ring (use the '.str()' method to see the entries)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_old[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3405.1740043645345"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(sparse_old[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 13, 16, ...,  0,  1,  1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sparse_old[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((sparse_new[0]-sparse_old[0]).numpy()!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2040 x 1635 sparse matrix over Integer Ring, 1277)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_old"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.6",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
