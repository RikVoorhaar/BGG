{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\mathrm H^{1}(\\wedge^2\\mathfrak b)=\\mathbb{C}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bggcohomology.bggcomplex import BGGComplex\n",
    "from bggcohomology.la_modules import LieAlgebraCompositeModule, ModuleFactory, BGGCohomology\n",
    "from bggcohomology.cohomology import compute_diff\n",
    "from bggcohomology.la_modules import BGGCohomology\n",
    "from bggcohomology.bggcomplex import BGGComplex\n",
    "from bggcohomology.quantum_center import *\n",
    "from bggcohomology.quantum_center import _compute_kernel, _compute_kernel2\n",
    "from bggcohomology.weight_set import WeightSet\n",
    "from bggcohomology.cohomology import compute_diff\n",
    "import numpy as np\n",
    "\n",
    "BGG = BGGComplex('G2')\n",
    "factory = ModuleFactory(BGG.LA)\n",
    "\n",
    "component_dic = {'b':factory.build_component('b','coad',subset=[])}\n",
    "\n",
    "wedge_components = [[(\"b\",2,'wedge')]]\n",
    "wedge_module = LieAlgebraCompositeModule(factory,wedge_components,component_dic)\n",
    "\n",
    "BGGCohomology(BGG, wedge_module).cohomology_LaTeX(complex_string = r'\\wedge^2\\mathfrak b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1]\n",
       "[-1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohom = BGGCohomology(BGG, wedge_module)\n",
    "\n",
    "sparse, _ = compute_diff(cohom, (0,0), 0, return_sparse=True)\n",
    "dense, _ = compute_diff(cohom, (0,0), 0, return_sparse=False)\n",
    "sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense._list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1260db7d49c14f7b8d6560b4d4b1fb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21eecc3c8164353ba4a39e34a249d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a68ab056eaf4babae7fa7dc20fc0ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "type A4, table for s=0:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{array}{r|l l}\n",
       "\t{\\scriptstyle i+j=6}&\\mathbb{C}^{33}&\\\\\n",
       "\t{\\scriptstyle i+j=10}&&\\mathbb{C}^{33}\\\\\n",
       "\t\\hline h^{i,j}&{\\scriptstyle j-i=0}&{\\scriptstyle j-i=4}\n",
       "\\end{array}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{array}{r|l l}\n",
       "\t{\\scriptstyle i+j=6}&33&\\\\\n",
       "\t{\\scriptstyle i+j=10}&&33\\\\\n",
       "\t\\hline h^{i,j}&{\\scriptstyle j-i=0}&{\\scriptstyle j-i=4}\n",
       "\\end{array}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{array}{rll}\n",
       "\t\\text{module}&\\text{multiplicity}&\\text{dimension} \\\\ \\hline \\text{all}&&66 \\\\\n",
       "\t\\mathbb{C}&66&1\n",
       "\\end{array}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%prun -D prun.log\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "os.makedirs('pickles', exist_ok=True)\n",
    "os.makedirs('tables', exist_ok=True)\n",
    "\n",
    "# Only compute cohomology for particular highest weight module\n",
    "mu = None\n",
    "#mu=(0,0)\n",
    "\n",
    "# the parameters we actually want to change\n",
    "diagram = 'A4'\n",
    "BGG = BGGComplex(diagram)\n",
    "subset=[]\n",
    "\n",
    "# compute only half of the table, extend by symmetry\n",
    "half_only = True\n",
    "extend_half = half_only\n",
    "\n",
    "# Exclude the top-left to bottom-right diagonal. If s=0, these should all be the trivial rep.\n",
    "exclude_diagonal = True\n",
    "\n",
    "# Display in full form\n",
    "compact = True\n",
    "\n",
    "# Load results if already computed\n",
    "load_pickle = False\n",
    "\n",
    "# Increase max memory size of the pari stack\n",
    "# Set this as high as possible.\n",
    "# pari.allocatemem(10^6,40*10^9)\n",
    "\n",
    "s=0\n",
    "#for method in [0,1]:\n",
    "#for s in itertools.count():\n",
    "method = 0\n",
    "for s in [0]:\n",
    "    picklefile = os.path.join('pickles',f'{diagram}-s{s}-{subset}.pkl')\n",
    "    if load_pickle and os.path.isfile(picklefile):\n",
    "        previous_cohom = pickle.load(open(picklefile, 'rb'))\n",
    "    else:\n",
    "        previous_cohom = None\n",
    "    texfile = os.path.join('tables',f'{diagram}-s{s}-{subset}.tex')\n",
    "    cohom_dic = dict()\n",
    "    with tqdm(all_abijk(BGG,s=s,subset=subset,half_only=half_only)[18:19]) as inner_pbar:\n",
    "        with tqdm(leave=None) as outer_pbar:\n",
    "            map_pbar = tqdm()\n",
    "            for a,b,i,j,k in inner_pbar:\n",
    "                if previous_cohom is not None and (a,b) in previous_cohom:\n",
    "                    cohom_dic[(a,b)]=previous_cohom[(a,b)]\n",
    "                    inner_pbar.update()\n",
    "                    continue\n",
    "                if exclude_diagonal and s==0 and (a==b):\n",
    "                    cohom_dic[(a,b)]=[((0,)*BGG.rank,1)]\n",
    "                    inner_pbar.update()\n",
    "                    continue\n",
    "                inner_pbar.set_description('i+j= %d, j-i = %d'%(a,b))\n",
    "                #coker = Eijk_basis(BGG,j,k,subset=subset,pbar=outer_pbar)\n",
    "                mjk = Mjk(BGG,j,k,subset=subset)\n",
    "                outer_pbar.set_description('Initializing cohomology')\n",
    "                coker=Eijk_basis(BGG,j,k,subset=subset,method=method)\n",
    "                cohom = BGGCohomology(BGG, mjk, \n",
    "                                      coker=coker,pbars = [outer_pbar,map_pbar])\n",
    "                outer_pbar.set_description('Computing cohomology')\n",
    "                cohom_list = cohom.cohomology(i, mu=mu)\n",
    "                cohom_dic[(a,b)] = cohom_list\n",
    "                with open(picklefile, 'wb') as f:\n",
    "                    pickle.dump(cohom_dic,f)   \n",
    "    print('-'*50)\n",
    "    print(f'type {diagram}, table for s={s}:')\n",
    "    cohom = BGGCohomology(BGG)\n",
    "    cohom_dic = extend_from_symmetry(cohom_dic)\n",
    "    latex_dic = {k:cohom.cohom_to_latex(c, compact=compact) for k,c in cohom_dic.items()}\n",
    "    betti_dic = {k:cohom.betti_number(c) for k,c in cohom_dic.items()}\n",
    "    tab1 = display_bigraded_table(latex_dic)\n",
    "    tab2 = display_bigraded_table(betti_dic)\n",
    "    tab3 = display_cohomology_stats(cohom_dic, BGG)\n",
    "    with open(texfile, 'w') as f:\n",
    "        f.write(prepare_texfile([tab1,tab2,tab3],title=f'type {diagram}, s={s}, subset={subset}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=10\n",
    "b=4\n",
    "i=3\n",
    "j=7\n",
    "k=-10\n",
    "mjk = Mjk(BGG,j,k,subset=subset)\n",
    "coker=Eijk_basis(BGG,j,k,subset=subset,method=method)\n",
    "cohom = BGGCohomology(BGG, mjk, coker=coker,pbars = [outer_pbar,map_pbar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bggcohomology.quantum_center.CokerCache object at 0x7f4ffc768ca0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 0), dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix([]).numpy(dtype=np.int_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "cython"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "# distutils: define_macros=CYTHON_TRACE_NOGIL=1\n",
    "# cython: profile=True\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sage.matrix.constructor import matrix\n",
    "from sage.rings.integer_ring import ZZ\n",
    "from sage.rings.rational import Rational\n",
    "from time import perf_counter\n",
    "\n",
    "cpdef compute_action(acting_element, action_source, module, comp_num):\n",
    "    \"\"\"Computes action of a single lie algebra element on a list of elements of the module. \n",
    "    Outputs a new array where indices and coefficients are replaced as per the action. \n",
    "    The output is unsorted, and may contain duplicate entries. \"\"\"\n",
    "\n",
    "    # Initialize array for output\n",
    "    action_image = np.zeros_like(action_source)\n",
    "\n",
    "    # Get component types. Each type has a different action of the Lie algebra\n",
    "    type_list = module.type_lists[comp_num]\n",
    "    cdef image_row = 0 # counter for which row to edit in output\n",
    "    cdef max_rows = len(action_image)\n",
    "\n",
    "    cdef int row,j\n",
    "    for col,mod_type in enumerate(type_list): # compute the action one column at a time\n",
    "        action_tensor = module.action_tensor_dic[mod_type] # retrieve the structure coefficient tensor\n",
    "        for row in range(len(action_source)):\n",
    "            j = action_source[row,col]\n",
    "            s,k,Cijk = action_tensor[acting_element,j]\n",
    "            while s!=0: # if s=0, then there are no non-zero structure coeffs\n",
    "                new_row = action_source[row].copy() # copy row, and change index to k\n",
    "                new_row[col] = k\n",
    "                new_row[-1]*=Cijk # multiply coefficient of element by structure coefficient C_ijk\n",
    "                action_image[image_row] = new_row\n",
    "                if s==-1: # end of the chain, break out of loop\n",
    "                    s=0\n",
    "                else: # still more non-zero C_ijk's to deal with\n",
    "                    s,k,Cijk = action_tensor[s,j]\n",
    "                image_row+=1\n",
    "                if image_row>=max_rows: # double size of image matrix if we run out of space\n",
    "                    action_image = np.concatenate([action_image,np.zeros_like(action_image)])\n",
    "                    max_rows = len(action_image)\n",
    "    return action_image[:image_row] # Only return non-zero rows\n",
    "\n",
    "cdef check_equal(long [:] row1,long [:] row2,int num_cols):\n",
    "    \"\"\"fast check to see if two arrays of given length are equal\"\"\"\n",
    "    cdef int i\n",
    "    for i in range(num_cols):\n",
    "        if row1[i]!=row2[i]:\n",
    "            return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "cdef col_nonzero(long [:] col, int num_rows):\n",
    "    \"\"\"returns non-zero indices of a column. np.nonzero doesn't seem to work well with memoryviews.\"\"\"\n",
    "\n",
    "    indices = np.zeros(num_rows,np.int32)\n",
    "    cdef int i\n",
    "    cdef int j = 0\n",
    "    for i in range(num_rows):\n",
    "        if col[i]!=0:\n",
    "            indices[j]=i\n",
    "            j+=1\n",
    "    return indices[:j]\n",
    "\n",
    "cdef merge_sorted_image(long [:,:] action_image):\n",
    "    \"\"\"Given sorted array, merges adjacent rows which are equal except for last column, \n",
    "    and adds the values of the last column\"\"\"\n",
    "    merged_image = np.zeros_like(action_image)\n",
    "\n",
    "    cdef long[:] old_row\n",
    "    cdef long[:] row\n",
    "    old_row = np.zeros_like(action_image[0])-1\n",
    "\n",
    "    cdef int row_number = -1\n",
    "    cdef int num_cols = action_image.shape[1]-1\n",
    "    cdef int num_rows = action_image.shape[0]\n",
    "\n",
    "    cdef int i\n",
    "    for i in range(num_rows):\n",
    "        row = action_image[i]\n",
    "        if row[-1]!=0:\n",
    "            if check_equal(row,old_row,num_cols): # if previous and current row are equal, add last column to result\n",
    "                merged_image[row_number,-1] += row[-1]\n",
    "            else:\n",
    "                row_number+=1\n",
    "                merged_image[row_number]=row\n",
    "                old_row = row\n",
    "    row_number+=1\n",
    "    non_zero_inds = col_nonzero(merged_image[:row_number,-1],row_number) # Only return rows where column is non-zero\n",
    "    return merged_image[non_zero_inds,:]\n",
    "\n",
    "def sort_merge(action_image):\n",
    "    \"\"\"Sorts array, ignoring last column and merges rows which are equal, summing in the last column\"\"\"\n",
    "    action_image = action_image[np.lexsort(np.transpose(action_image[:,:-1]))]\n",
    "    return merge_sorted_image(action_image)\n",
    "\n",
    "cdef permutation_sign(long [:] row,int num_cols):\n",
    "    \"\"\"Computes the sign of a permutation using bubble sort (efficient for extremely short inputs)\"\"\"\n",
    "    cdef int sign = 1\n",
    "    cdef int i,j\n",
    "    for i in range(num_cols):\n",
    "        for j in range(i+1,num_cols):\n",
    "            if row[i]==row[j]: # if there are duplicate entries then sign is 0 per definition\n",
    "                return 0\n",
    "            elif row[i]>row[j]: # For each swap we have to do, the sign changes by -1.\n",
    "                sign*=-1\n",
    "    return sign\n",
    "\n",
    "cdef sort_cols(module, action_image,comp_num):\n",
    "    \"\"\"Sort all the entries of each tensor component. If tensor component is a wedge power, then\n",
    "    mutliply coefficient by sign of permutation sorting the row.\"\"\"\n",
    "    cdef int col_min = 0\n",
    "    cdef int num_rows = len(action_image)\n",
    "    cdef int i\n",
    "    cdef long[:] row\n",
    "\n",
    "    for _,cols,mod_type in module.components[comp_num]:\n",
    "        if cols>1: # List with one item is always sorted\n",
    "            if mod_type == 'wedge':\n",
    "                for i in range(num_rows):\n",
    "                    row = action_image[i,col_min:col_min+cols]\n",
    "                    action_image[i,-1]*=permutation_sign(row,cols) # Change coefficient by sign of permutation\n",
    "            action_image[:,col_min:col_min+cols] = np.sort(action_image[:,col_min:col_min+cols]) # sort the rows\n",
    "        col_min+=cols\n",
    "\n",
    "cpdef action_on_basis(pbw_elt,wmbase,module,factory,comp_num):\n",
    "    \"\"\"Computes the action of an element of U(n) in PBW order on a basis of the weight component.\n",
    "    Input is the PBW element, the basis of the weight component,\n",
    "    the factory that created the module, and the number of the direct sum component\"\"\"\n",
    "\n",
    "    num_cols = wmbase.shape[1]\n",
    "    action_list = []\n",
    "    action_source = np.zeros((wmbase.shape[0], num_cols+2),np.int64)\n",
    "    action_source[:,:num_cols] = wmbase\n",
    "    action_source[:,num_cols] = np.arange(len(wmbase))\n",
    "    action_source[:,-1] = 1\n",
    "\n",
    "    # Compute action for each monomial seperately, and then sum results\n",
    "    for monomial,coefficient in pbw_elt.monomial_coefficients().items():\n",
    "        action_image = action_source.copy()\n",
    "        action_image[:,-1]*=coefficient # mutliply results by coefficient of monomial\n",
    "        for term in monomial.to_word_list()[::-1]: # Right action, so we take terms of the monomial in inverse order\n",
    "            index = factory.root_to_index[term] # get the index of the term\n",
    "            action_image = compute_action(index, action_image, module, comp_num) # compute the action\n",
    "        action_list.append(action_image)\n",
    "    action_image = np.concatenate(action_list) # concatenate and merge is equivalent to summing the results.\n",
    "    if len(action_image)==0: # merging gives errors for empty matrices\n",
    "        return action_image\n",
    "    else:\n",
    "        sort_cols(module,action_image,comp_num) # Sort and merge\n",
    "        action_image = sort_merge(action_image)\n",
    "\n",
    "        return action_image\n",
    "\n",
    "def check_weights(module,action_image):\n",
    "    weights = set()\n",
    "    for row in action_image[:,:-2]:\n",
    "        mu = sum(module.weight_dic[s] for s in row)\n",
    "        weights.add(tuple(mu))\n",
    "    if len(weights)>1:\n",
    "        raise ValueError(\"Found too many weights :(\")\n",
    "\n",
    "def compute_diff_new(cohom, mu, i, return_sparse=False):\n",
    "    \"\"\"\"\n",
    "    Computes the BGG differential associated to a BGGCohomology object, weight mu and degree i.\n",
    "    The matrix produced is of the correct rank, but omits some rows consisting entirely of zeros.\n",
    "    In order to correctly compute kernel, the dimension of the source space is therefore also returned.\n",
    "    \"\"\"\n",
    "    # aliases\n",
    "    BGG = cohom.BGG\n",
    "    module = cohom.weight_module\n",
    "    factory =  module.factory\n",
    "\n",
    "    # weights associated to each vertex of the Bruhat graph\n",
    "    vertex_weights = cohom.weight_set.get_vertex_weights(mu)\n",
    "\n",
    "    # maps of the BGG complex\n",
    "    maps = BGG._maps[mu]\n",
    "\n",
    "    # for each vertex, get the arrows in the Bruhat graph going out of it.\n",
    "    column = BGG.column[i]\n",
    "    delta_i_arrows = [(w, [arrow for arrow in BGG.arrows if arrow[0] == w]) for w in column]\n",
    "\n",
    "    # Look up vertex weights for the target column\n",
    "    target_column = BGG.column[i+1]\n",
    "    target_col_dic = {w:vertex_weights[w] for w in target_column}\n",
    "\n",
    "    # To give the weights in the target column a unique index, we compute\n",
    "    # an offset for each weight component in the target column\n",
    "    offset = 0\n",
    "    for w,mu in target_col_dic.items():\n",
    "        target_col_dic[w] = offset\n",
    "        if cohom.has_coker and (mu in cohom.coker):\n",
    "            offset+=cohom.coker[mu].nrows() # Dimension of quotient is number of rows\n",
    "        else:\n",
    "            if mu in module.dimensions:\n",
    "                offset+=module.dimensions[mu]\n",
    "\n",
    "    # Compute dimension of source space by adding dimensions of weight components in the column\n",
    "    source_dim = 0\n",
    "    for w in column:\n",
    "        initial_vertex = vertex_weights[w]\n",
    "        if initial_vertex in cohom.weights:\n",
    "            if cohom.has_coker and (initial_vertex in cohom.coker):\n",
    "                source_dim += cohom.coker[initial_vertex].nrows() # dimension of quotient is number of rows\n",
    "            else:\n",
    "                source_dim += cohom.weight_module.dimensions[initial_vertex]\n",
    "\n",
    "\n",
    "    offset = 0\n",
    "    total_diff=[]\n",
    "    for w, arrows in delta_i_arrows:\n",
    "        initial_vertex = vertex_weights[w]  # weight of vertex\n",
    "        if initial_vertex in cohom.weights:  # Ensure weight component isn't empty\n",
    "            action_images = []\n",
    "            for a in arrows: # Compute image for each arrow\n",
    "                final_vertex = vertex_weights[a[1]]\n",
    "\n",
    "                sign = BGG.signs[a] # Multiply everything by the sign of the map in BGG complex\n",
    "\n",
    "                comp_offset_s = 0\n",
    "\n",
    "                for comp_num,weight_comp in module.weight_components[initial_vertex]:\n",
    "                    # compute the action of the PBW element\n",
    "                    # map is multiplied by sign. Need to convert sign to Rational to avoid errors in newer sage version\n",
    "                    basis_action = action_on_basis(maps[a]*Rational(sign),weight_comp,module,factory,comp_num)\n",
    "\n",
    "                    basis_action[:,-2] += comp_offset_s # update source\n",
    "                    comp_offset_s += module.dimensions_components[comp_num][initial_vertex]\n",
    "\n",
    "                    # If there is a cokernel, we have reduce the image of the action\n",
    "                    # to the basis of the quotient module\n",
    "                    if cohom.has_coker:\n",
    "                        try:\n",
    "                            basis_action = coker_reduce(cohom.weight_module,cohom.coker, basis_action,\n",
    "                                                        initial_vertex, final_vertex,\n",
    "                                                        component=comp_num)\n",
    "                        except IndexError as err:\n",
    "                            print(final_vertex)\n",
    "                            raise err\n",
    "\n",
    "                        if len(basis_action)>0:\n",
    "                            basis_action[:,0]+=target_col_dic[a[1]] # offset for weight module\n",
    "                            action_images.append(basis_action)\n",
    "\n",
    "                    # The cokernel reduction automatically inserts appropriate offsets for indices\n",
    "                    # In the non-cokernel case we still have to do this manually\n",
    "                    if len(basis_action)>0:\n",
    "                        if not cohom.has_coker:\n",
    "                            new_basis_action = np.zeros(shape=(basis_action.shape[0],3),dtype=basis_action.dtype)\n",
    "\n",
    "\n",
    "\n",
    "                            # Convert the sets of indices [i1,...,ik] into a single index for the whole weight component\n",
    "                            # We do this by looking the index i up in a dictionary.\n",
    "                            target_basis_dic = module.weight_comp_index_numbers[final_vertex]\n",
    "                            num_cols = basis_action.shape[1]-2\n",
    "                            for i,row in enumerate(basis_action):\n",
    "                                j = target_basis_dic[tuple(list(row[:num_cols])+[comp_num])]\n",
    "                                new_basis_action[i][0]=j\n",
    "                                new_basis_action[i][1:] = row[num_cols:]\n",
    "                            new_basis_action[:,0]+=target_col_dic[a[1]]\n",
    "\n",
    "                            action_images.append(new_basis_action)\n",
    "\n",
    "            if len(action_images)>0:\n",
    "                # Concatenate images for each arrow to get total image\n",
    "                sub_diff = np.concatenate(action_images)\n",
    "\n",
    "                # Each basis element of weight component gets index\n",
    "                # Because we have multiple weight components, we need to add a number to this index\n",
    "                # So that index remains unique across multiple components\n",
    "\n",
    "                sub_diff[:,-2]+=offset\n",
    "\n",
    "                offset+=module.dimensions[initial_vertex]\n",
    "                total_diff.append(sub_diff)\n",
    "\n",
    "\n",
    "    if len(total_diff)>0: # Sometimes action is trivial, would otherwise raise errors\n",
    "        total_diff = np.concatenate(total_diff)\n",
    "        total_diff = sort_merge(total_diff) # for cokernels we can get duplicate entries. We need to merge them.\n",
    "        total_diff = total_diff[np.lexsort(np.transpose(total_diff[:,:-2]))]  # Sort by source indices\n",
    "\n",
    "    if len(total_diff) ==0: # Trivial differential\n",
    "        return matrix(ZZ,0,0),source_dim\n",
    "\n",
    "     # encode as sparse matrix. each entry is triple of two indices and the value at the two indices\n",
    "    diff_entries = np.zeros((len(total_diff),3),np.int64)\n",
    "    j = -1\n",
    "\n",
    "    # If two entries represent the same element in source column, put them in same row j.\n",
    "    # This loop merges this an populates a sparse matrix with correct row numbers.\n",
    "\n",
    "    prev_row = np.zeros_like(total_diff[0,:-2])-1  # every row is different from this one\n",
    "    for i in range(len(total_diff)):\n",
    "        row_num = i\n",
    "        row = total_diff[i,:-2]\n",
    "        if np.any(np.not_equal(row,prev_row)): # if row is different, it will have different index\n",
    "            j+=1\n",
    "            prev_row = row\n",
    "        diff_entries[row_num,0] = j # populate sparse matrix\n",
    "        diff_entries[row_num,1:] = total_diff[i,-2:]\n",
    "    j+=1\n",
    "\n",
    "    if return_sparse:\n",
    "        d_sparse = matrix(ZZ, {(a,b): c for a, b, c in diff_entries}, sparse=True)\n",
    "        return d_sparse, source_dim\n",
    "\n",
    "    # turn sparse differential matrix into dense one.\n",
    "    d_dense = matrix(ZZ,j,max(diff_entries[:,1])+1)\n",
    "    for i in range(len(diff_entries)):\n",
    "        d_dense[diff_entries[i,0],diff_entries[i,1]] = diff_entries[i,2]\n",
    "\n",
    "    return d_dense, source_dim\n",
    "\n",
    "def coker_reduce(target_module, coker, long[:,:] action_image, mu0, mu1, component=0):\n",
    "    \"\"\"Projects source and target of an action in the coker quotient coker(f), f:M->N.\n",
    "    Returns action in the basis of the cokernel.\n",
    "    `source_module` is the module M\n",
    "    `target_module` is the module N\n",
    "    `coker` is a dictionary encoding a basis of the coker in each weight component of N\n",
    "    `action_image` is what action_on_basis returns.\n",
    "    `component` is the index of the direct sum component\n",
    "    We assume we acted with a map `mu0`->`mu1` in action_on_basis.\n",
    "    \"\"\"\n",
    "    # the input is always of shape [i1,i2,..,ik,j,c] where i denotes the indices\n",
    "    # of the target, j the source index, and c the coefficient.\n",
    "    # then `num_cols` denotes this number k.\n",
    "    # print(\"init\")\n",
    "    current_time = perf_counter()\n",
    "    cdef size_t num_cols = action_image.shape[1]-2\n",
    "\n",
    "    # If mu1 is not in the module, then it has to be zero\n",
    "    if mu1 not in target_module.weight_components:\n",
    "        return []\n",
    "\n",
    "    # Convert the sets of indices [i1,...,ik] into a single index i for the whole weight component\n",
    "    # We do this by looking the index i up in a dictionary.\n",
    "    target_basis_dic = target_module.weight_comp_index_numbers[mu1]\n",
    "    cdef size_t num_action_rows = action_image.shape[0]\n",
    "    cdef long[:,:] action_image_target = np.zeros((num_action_rows, 3),dtype=np.int_)\n",
    "    cdef long[:,:] new_action_image\n",
    "    cdef long i, j, k\n",
    "    cdef long[:] row\n",
    "    # for i,row in enumerate(action_image):\n",
    "    for i in range(num_action_rows):\n",
    "        row = action_image[i]\n",
    "        j = target_basis_dic[tuple(list(row[:num_cols])+[component])]\n",
    "        action_image_target[i][0]=j\n",
    "        action_image_target[i][1:] = row[num_cols:]\n",
    "    \n",
    "    # print(f\"part1: {perf_counter()-current_time}\")\n",
    "    current_time = perf_counter()\n",
    "\n",
    "    # If mu0 is in the cokernel dictionary, express the action in the basis of the quotient\n",
    "    # If not, then the basis of the quotient is equal to the basis of the module, so there's nothing to do\n",
    "    cdef int current_row\n",
    "    cdef long[:,:] new_images\n",
    "    cdef long[:,:] coker_mat\n",
    "    cdef size_t num_coker_rows\n",
    "    if mu0 in coker:\n",
    "        # If target vector space is zero, return empty matrix\n",
    "        coker_mat = coker[mu0].numpy()\n",
    "        num_coker_rows = coker_mat.shape[0]\n",
    "        if coker_mat.shape[0]==0:\n",
    "            return np.array([])\n",
    "        new_images = np.zeros((action_image.shape[0]*coker_mat.shape[1],3),dtype=np.int_)\n",
    "        current_row = 0\n",
    "        for k in range(num_action_rows):\n",
    "        # for action_row in action_image_target:\n",
    "            target = action_image_target[k][0]\n",
    "            source = action_image_target[k][1]\n",
    "            coeff = action_image_target[k][2]\n",
    "            # for i,c in enumerate(coker[mu0][:,source]):\n",
    "            for i in range(num_coker_rows):\n",
    "                c = coker[mu0][i,source]\n",
    "                if c!=0:\n",
    "                    new_images[current_row][0] = target\n",
    "                    new_images[current_row][1] = i\n",
    "                    new_images[current_row][2] = coeff * c\n",
    "                    current_row+=1\n",
    "        new_action_image = new_images[:current_row]\n",
    "    else:\n",
    "        new_action_image = action_image_target\n",
    "    \n",
    "    # print(f\"part2: {perf_counter()-current_time}\")\n",
    "    current_time = perf_counter()\n",
    "\n",
    "    # If mu1 is in the cokernel dictionary, then reduce the image to the quotient\n",
    "    # We do this by multiplying by the matrix encoding the basis of the cokernel\n",
    "    # If it's not in the dictionary, no reduction is necessary.\n",
    "    cdef long[:,:] new_image_coker\n",
    "    cdef size_t nrows_new_action_image = new_action_image.shape[0]\n",
    "    cdef long[:] action_row\n",
    "    if mu1 in coker:\n",
    "        coker_mat = coker[mu1].numpy()\n",
    "        num_coker_rows = coker_mat.shape[0]\n",
    "\n",
    "        # If target vector space is zero, return empty matrix\n",
    "        if coker[mu1].nrows()==0:\n",
    "            return np.array([])\n",
    "        new_image_coker = np.zeros((new_action_image.shape[0]*coker[mu1].ncols(),3),dtype=np.int_)\n",
    "        current_row = 0\n",
    "\n",
    "        for k in range(nrows_new_action_image):\n",
    "            # action_row = new_action_image[k]\n",
    "        # for action_row in new_action_image:\n",
    "            j = new_action_image[k][0]\n",
    "            # for i,c in enumerate(coker[mu1][:,j]):\n",
    "            for i in range(num_coker_rows):\n",
    "                c = coker_mat[i,j]\n",
    "                if c!=0:\n",
    "                    # new_image_coker[current_row]=action_row\n",
    "                    new_image_coker[current_row][0]=i\n",
    "                    new_image_coker[current_row][1]=new_action_image[k][1]\n",
    "                    new_image_coker[current_row][2]=new_action_image[k][2]*c\n",
    "                    current_row+=1\n",
    "    else:\n",
    "        new_image_coker = new_action_image\n",
    "        current_row = len(new_image_coker)\n",
    "\n",
    "    # print(f\"part3: {perf_counter()-current_time}\")\n",
    "\n",
    "    # At the end of the day, sort the result and sum coefficients of identical (source, target) tuples.\n",
    "    # If the final matrix is empty, instead we just return an empty array to avoid errors.\n",
    "    if current_row>0:\n",
    "        return sort_merge(np.array(new_image_coker[:current_row]))\n",
    "    else:\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_new = compute_diff_new(cohom,(0,0,0,0),i,return_sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bggcohomology.cohomology import compute_diff\n",
    "\n",
    "sparse_old = compute_diff(cohom,(0,0,0,0),i,return_sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((sparse_new[0]-sparse_old[0]).numpy()!=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.6",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
